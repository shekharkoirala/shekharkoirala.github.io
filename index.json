[{"content":"Background In this case study, Artificial Intelligence based system is used to take buisness decisions. The study is based on a e-commerce company which ingest lots of data like images, quarterly reports, invoices, customer feedbacks, customer reviews with images, etc. It would be great if this large amount of data is automatically categorized or grouped together. Previously, a machine learning team in the company had created a model to classify the input data. But the nature of the e-commerce data, new product launches, new customer feedbacks, etc. are not predictable. Thus, the model needs to be retrained frequently. The company is looking for a solution that can automatically perform and help the analyst to get the insight from the unstructured data.\nImage Clustering Lets dive in the Technical side of the case study. There are multiple paradigms of supervised machine learning, such as classification, object detection, and segmentation, among others. There are many robust supervised algorithms; however, to achieve high accuracy, we need labeled data, which is costly and time-consuming. Clustering is an unsupervised learning technique that can be applied to unlabeled datasets. It is one of the most interesting and challenging problems in the field of computer vision. The goal of image clustering is to group similar images together in the same cluster. There are also other forms of machine learning, such as semi-supervised learning, reinforcement learning, and transfer learning, which are not covered in this article. The main goal of the article is to explore the image clustering technique beyond its traditional use cases.\nImage clustering: View from Professional settings In real world scenario, a company could ingest images from multiple sources. The image sizes / format , interest point in the image are unknown. To fetch the insight from the unstructure settings is really hard and requires alot of regular hand picked tuning. Thus, Many companies moves towards supervised learning where they sample the data and label them and train a supervised model to get the insight.\nHowever, the unsupervised learning is also a good choice when the data is unpredictable and the labels are not available. The image clustering is one of the unsupervised learning technique which can be used to cluster the images based on the similarity and thus using this in the automated workflow to get the insight from the unstructured data.\nMethodology Image clustering systems can be divided into two main categories:\n Image feature Generation Image pixels are stored as matrics in the computer. The size of image matrics varies based on the image size and format. Thus Image pixel couldnot be used directly to custering algorithm due to its size and variability. Image features can be generated using various methods like neural networks, computer vision algorithms like SIFT, SURF, ORB, etc. Sometimes feature reduction techniques like PCA, LDA, etc are used to reduce the dimensionality of the features. Feature clustering After a feature is generated, the clustering algorithm is applied to the features to cluster the images. The clustering algorithm can be K-means, DBSCAN, Hierarchical clustering, etc.  for the sake of this study, we are using a small dataset of brand logos. However in the study properitery e-commerce data [ logos from pdfs/ document ] are used. Note: It really depends on the company data, sometimes the whole image are used to generate the features and sometimes the interest points are used to generate the features. Segment Anything model can be used to generate the interest points. Here, an invoice is parsed by the model when the text prompt is logo and the bounding box over the Tesla logo is generated.\nModel Web Demo: Segment Anything\nImage Feature Generation The latest trend of Attention based models outperforms the traditional computer vision algorithms. The attention based models like ViT, ResNet, EfficientNet, etc are used to generate the features. Likewise, there are multi model models like CLIP, DALL-E, etc which are used to generate the features. Using the multi model models, the features can be used to compared with the possible text data and thus can be used to generate the insight from the images.\nfor the example of the image clustering, we will be using the openAI\u0026rsquo;s CLIP model to generate the features.\n1 2 3 4  from transformers import AutoProcessor, AutoTokenizer, CLIPModel model = CLIPModel.from_pretrained(\u0026#34;openai/clip-vit-large-patch14\u0026#34;) processor = AutoProcessor.from_pretrained(\u0026#34;openai/clip-vit-large-patch14\u0026#34;)   a good alternative to the CLIP model is the VIT model.\n1 2 3 4  from transformers import ViTImageProcessor, ViTForImageClassification processor = ViTImageProcessor.from_pretrained(\u0026#39;google/vit-base-patch16-224\u0026#39;) model = ViTForImageClassification.from_pretrained(\u0026#39;google/vit-base-patch16-224\u0026#39;)   Resource to browse the models for feature generation: Huggingface\nOnce the model is loaded, we can generate the features using the model.\n1 2 3  with torch.no_grad(): inputs = processor(images=batch_images, return_tensors=\u0026#34;pt\u0026#34;) image_feature_data = model.get_image_features(**inputs)   It is important that the processor should be feed in the batch image data. since the the underlying model is trained on the batch image data. Thus batch image helps to achieve better throughput for generating the features.\nImage clustering Algorithm Once the features are generated, the clustering algorithm is applied to the features. The clustering algorithm can be K-means, DBSCAN, Hierarchical clustering, etc. Here, we choose Faiss for the clustering as it has both CPU and GPU support.\n1 2 3 4 5 6 7 8  import faiss n_centroids = 5 # number of clusters n_iter = 100 # number of iterations verbose = True feature_data_dim = feature_data.shape[1] # dimension of the feature data kmeans = faiss.Kmeans(feature_data_dim, ncentroids, niter=niter, verbose=verbose) kmeans.train(feature_data)   Lets see How it creates the cluster. The image clustering result doesnot make sense. lets update the hyperparamter and create the clustering again with different number of clusters.\n1  n_centroids = 35 # number of clusters   The clustering result is much better. The cluster result is better than the previous as we increased the number of clusters. The number of clusters can be determined based on the domain knowledge of the dataset or using the metrics.\nImage clustering Metrics Finding the best cluster size is a challengine task. The perfect cluster size can be predicted if some domain knowledge of the dataset is available. In the absence of domain knowledge, we can use the metrics to find the best cluster size.\nImage clustering can be compared based on two types of metrics.\n Extrinsic metrics: Extrinsic metrics are based on the ground truth labels. Some of the popular extrinsic metrics are:  Adjusted Rand Index (ARI) Normalized Mutual Information (NMI) Fowlkes-Mallows Index (FMI) Homogeneity, Completeness, and V-measure Precision, Recall, and F1-score Confusion matrix     However, we are into the unsupervised learning, we will not be using these metrics.\nIntrinsic metrics: Intrinsic metrics are based on the clustering results. Some of the popular intrinsic metrics are:  Silhouette score Davies-Bouldin Index Calinski-Harabasz Index Gap statistic Elbow method    Lets see how we can use these metrics to evaluate the clustering results.\nThe blog only highlights the specfic part of the image clustering system. All the necessary code snippets are provided to get started with the image clustering. Many software enhancement and glue code are skipped for the sake of the article.\nResult A image clustering system is created and implemented in the system and the data is forwarded to the analyst for the further analysis. The system is able to cluster the data based on the cluster and thus necessary action can be taken much faster. As the system is automated, many documents gets labelled eventually and thus labelling the cluster is much easier than labelling the whole dataset.\n","permalink":"http://shekharkoirala.github.io/posts/image_clustering_intro/","summary":"Background In this case study, Artificial Intelligence based system is used to take buisness decisions. The study is based on a e-commerce company which ingest lots of data like images, quarterly reports, invoices, customer feedbacks, customer reviews with images, etc. It would be great if this large amount of data is automatically categorized or grouped together. Previously, a machine learning team in the company had created a model to classify the input data.","title":"Case study: Automated Image Clustering for E-commerce company"},{"content":"","permalink":"http://shekharkoirala.github.io/posts/data_sourcing_ml/","summary":"","title":"Data_sourcing_ml"},{"content":"This is based on a workshop on Pycon Ireland 2023 given by : Pavlo Tishkin\n Setup AWS account Setup AWS CLI Setup Terraform Setup Python Setup AWS credentials Setup AWS S3 bucket Setup AWS Lambda function Setup AWS CloudWatch event Setup AWS IAM role Setup AWS IAM policy setup lamda function  \u0026laquo; updating soon\u0026raquo;\n","permalink":"http://shekharkoirala.github.io/posts/terraform_aws_python/","summary":"This is based on a workshop on Pycon Ireland 2023 given by : Pavlo Tishkin\n Setup AWS account Setup AWS CLI Setup Terraform Setup Python Setup AWS credentials Setup AWS S3 bucket Setup AWS Lambda function Setup AWS CloudWatch event Setup AWS IAM role Setup AWS IAM policy setup lamda function  \u0026laquo; updating soon\u0026raquo;","title":"Terraform_aws_python"},{"content":"How to install luminance HDR in ubuntu  install dependecies  1  sudo apt install -y qtcreator qtbase5-dev qt5-qmake cmake libexiv2-dev libtiff-dev libraw-dev libpng-dev libjpeg-dev libopenexr-dev libfftw3-dev libboost-all-dev libcfitsio-dev libgsl-dev   This command installs the following dependencies:\n QT5 development tools exiv2 library libtiff library libraw library libpng library libjpeg library libopenexr library fftw3 library libboost library cfitsio library Gnu Gsl library  sudo apt install qttools5-dev sudo apt-get install qttools5-dev-tools sudo apt install libqt5webkit5-dev sudo apt-get install libqt5svg5-dev sudo apt-get install libeigen3-dev\n install luminance hdr\n1 2 3 4 5 6 7 8 9 10 11 12  git clone cd luminance-hdr mkdir build cd build cmake \\  5s 12:07:11 PM -DCMAKE_BUILD_TYPE=\u0026#34;Release\u0026#34; \\ -DCMAKE_INSTALL_PREFIX=\u0026#34;$HOME/programs/lhdr\u0026#34; \\ .. make sudo make install     ","permalink":"http://shekharkoirala.github.io/posts/install_luminance_ubuntu/","summary":"How to install luminance HDR in ubuntu  install dependecies  1  sudo apt install -y qtcreator qtbase5-dev qt5-qmake cmake libexiv2-dev libtiff-dev libraw-dev libpng-dev libjpeg-dev libopenexr-dev libfftw3-dev libboost-all-dev libcfitsio-dev libgsl-dev   This command installs the following dependencies:\n QT5 development tools exiv2 library libtiff library libraw library libpng library libjpeg library libopenexr library fftw3 library libboost library cfitsio library Gnu Gsl library  sudo apt install qttools5-dev sudo apt-get install qttools5-dev-tools sudo apt install libqt5webkit5-dev sudo apt-get install libqt5svg5-dev sudo apt-get install libeigen3-dev","title":"Install_luminance_ubuntu"},{"content":"How to use your XT1/2/3/4 fujifilm camera as webcam for your ubuntu 22.04. This is a simple guide to use your fujifilm camera as a webcam.\nInstallation: 1  sudo apt-get install gphoto2 v4l2loopback-utils v4l2loopback-dkms ffmpeg   modprobe setup\n1 2 3  sudo modprobe -r v4l2loopback sudo modprobe v4l2loopback exclusive_caps=1 max_buffers=2   check video sources\n1  ls -l /dev/video*   Make sure there is no gphoto process already running:\n1  ps aux | grep gphoto   check is camera is detected by gphoto2:\n1  gphoto2 --auto-detect   start the webcam\n1  gphoto2 --stdout --capture-movie | ffmpeg -i - -vcodec rawvideo -pix_fmt yuv420p -threads 0 -f v4l2 /dev/video2   Note: Huge thanks to : https://medium.com/nerdery/dslr-webcam-setup-for-linux-9b6d1b79ae22\n","permalink":"http://shekharkoirala.github.io/posts/fujifilm_as_webcam/","summary":"How to use your XT1/2/3/4 fujifilm camera as webcam for your ubuntu 22.04. This is a simple guide to use your fujifilm camera as a webcam.\nInstallation: 1  sudo apt-get install gphoto2 v4l2loopback-utils v4l2loopback-dkms ffmpeg   modprobe setup\n1 2 3  sudo modprobe -r v4l2loopback sudo modprobe v4l2loopback exclusive_caps=1 max_buffers=2   check video sources\n1  ls -l /dev/video*   Make sure there is no gphoto process already running:","title":"Fujifilm_as_webcam"},{"content":"ffmpeg Recipes A list of useful receipes when using ffmpeg. A dump for future references.\n  Extract frames from video:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #!/bin/zsh # Find all .mp4 files in the current directory and store them in an array input_files=(*.mp4) # Loop through each input file for input_file in \u0026#34;${input_files[@]}\u0026#34; do # Get the path to the input file directory input_dir=\u0026#34;$(dirname \u0026#34;$input_file\u0026#34;)\u0026#34; # Create a folder for the input file images in the same directory as the input file folder_name=\u0026#34;${input_file%.*}_images\u0026#34; output_dir=\u0026#34;$input_dir/$folder_name\u0026#34; mkdir -p \u0026#34;$output_dir\u0026#34; # Extract images from the input file and save them to the folder ffmpeg -i \u0026#34;$input_file\u0026#34; -r 1 \u0026#34;$output_dir/output_%03d.png\u0026#34; done     combine video.mp4 and audio.mp4 to a single video.\n1  ffmpeg -i video.mp4 -i audio.mp4 -c copy -map 0:0 -map 1:1 -shortest combined.mp4     convert .h265 video to .h264\n1  ffmpeg -i video1.mov -vcodec h264 -acodec mp2 video1.mp4     ","permalink":"http://shekharkoirala.github.io/posts/fury_ffmpeg/","summary":"ffmpeg Recipes A list of useful receipes when using ffmpeg. A dump for future references.\n  Extract frames from video:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  #!/bin/zsh # Find all .mp4 files in the current directory and store them in an array input_files=(*.mp4) # Loop through each input file for input_file in \u0026#34;${input_files[@]}\u0026#34; do # Get the path to the input file directory input_dir=\u0026#34;$(dirname \u0026#34;$input_file\u0026#34;)\u0026#34; # Create a folder for the input file images in the same directory as the input file folder_name=\u0026#34;${input_file%.","title":"Fast Fury and Fantastic .... The ffmpeg"},{"content":"Introduction The post is a quick guide on \u0026ldquo;How we could use AWS lambda services to deploy some standalone task\u0026rdquo;. This is really helpful when we dont have to buy instances for such task. By using word task, I mean scripts, that could scrap data, or a cron job data aggregator. The BEST thing about the cron job is that , it is way cheaper. A million hits by lambda function is Free in AWS.\nThe following steps could lets you get going. In this example below, I am aggregating data in MongoDB and store the output in Redis.\nStep 1 function creating Create function : https://console.aws.amazon.com/lambda/home?region=us-east-1 One has to login to the AWS console and create a lambda function. Think Lambda function as a task that we want to do here.\nTo run a function , we need a script. Lets say : lambda_function.py The script wont run until it mets all its dependency. In Data Science world, pandas , numpy etc. We need to provide all the Dependency a script it requires.\nStep 2 Dependencies For managing the Dependencies : we could looked at the official Documentation. https://docs.aws.amazon.com/lambda/latest/dg/python-package.html In short: We want to dump all the dependencies in a folder.\n1 2 3  pip install --target ./package redis pip install --target ./package sentry_sdk pip install --target ./package motor   Yeah, I didnt include pandas, numpy and scipy. Because that is different case. The AWS lambda works in different version of linux which doesnt support the pypi installation of pandas and numpy. As those libraries extensibly use cython for optimization.\nTo use such Libraries, we will get to the new concept of Lmbda function ie : LAYERS\nstep 3: the code Make your code ready, especially the Beginning and the end. Most of the standard python use config.ini or .env file to get the variables value. Change that to os.environ.gte() function.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  import motor.motor_asyncio import asyncio from datetime import datetime, timedelta import os import pandas as pd import sentry_sdk import redis import json class TrendingAggregator: def __init__(self): sentry_url = os.environ.get(\u0026#34;default\u0026#34;, \u0026#34;sentry_url\u0026#34;) sentry_env = os.environ.get(\u0026#34;default\u0026#34;, \u0026#34;sentry_env\u0026#34;)   Similarly, at the end of the code.\n1 2 3  def lambda_handler(event, context): trending = TrendingAggregator() trending.process()   You could change the function name lambda_handler and the filename lambda_function.py but it requires you to change the name in AWS lambda function console too. So, for sake of lazyness, lets stick to the default naming.\nStep 4: shipment Make the shipment ready.\n1 2 3 4 5  ~/my-function$ cd package ~/my-function/package$ zip -r9 ${OLDPWD}/function.zip . $ cd .. $ zip -g function.zip lambda_function.py   Here, what we did is , we zipped the packages [ dependencies ] and then add our script to the function.zip file.\nStep 5: layers ? You could see Function code, when you scroll down in the lambda dunction page in your AWS console , and Actions box, where one get options like upload a .zip file or upload a file from Amazon S3 Once you upload your zip file. You will see your code [ unless your code is more that 10 MB ]\nThere you could save and test the code. But since you need more complex dependencies You need to know little mroe about layers.\nStep 5 : yeah, the layers. Layers: If your code depends on AWS lambda function layers, you could do Three things to solve this. link to add layer to your lambda function https://console.aws.amazon.com/lambda/home?region=us-east-1#/add/layer?function=trending_aggregator Note: trending-aggregator is my function name.\nuse standard layer more info https://aws.amazon.com/blogs/aws/new-for-aws-lambda-use-any-programming-language-and-share-common-components/ its easy, its provided by AWS ( safe )\nOne could select Select from list of runtime compatible layers when they are in their layer page and see the AWS standard layer name. AWSLambda-Python6-SciPy1x\nuse someone else layer yeah, well, whatever you gonna do, someone had already done it may be 5 years ago. So, you could use their layer. Until you have their layer code. Luckily someone shares the detail in a stackoverfflow question. Cheers. more info https://stackoverflow.com/questions/36054976/pandas-aws-lambda One could select Provide a layer version ARN in their layer page. and add this arn code arn:aws:lambda:us-east-1:113088814899:layer:Klayers-python37-pandas:1 BOOM , Thanks Mate.\nuse your own layer Security Issues ?, To create our own layer , we need another AWS machine ( EC2). Login to another EC2 machine and follow these steps:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  python --version Python 3.6.8 # https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html # python 3.6 uses Amazon Linux currently  mkdir project cd project virtualenv v-env source ./v-env/bin/activate pip install pandas deactivate # creating layer # https://docs.aws.amazon.com/lambda/latest/dg/configuration-layers.html#configuration-layers-path mkdir python cd python cp -r ../v-env/lib/python3.6/site-packages/* . cd .. zip -r panda_layer.zip python   This will create a zip file which include pandas , as installed natively in a weird AWS machine.\n1 2 3 4 5 6 7 8 9  ubuntu@ip:~/project$ cd ~/.aws/ ubuntu@ip:~/.aws$ ls config credentials credentials_prod ubuntu@ip:~/.aws$ cp credentials credentials_dev ubuntu@ip:~/.aws$ aws configure AWS Access Key ID [****************VF5Q]: *********AWS Id ************ AWS Secret Access Key [****************hco4]: *********AWS access key ************ Default region name [us-east-1]: Default output format [json]:   Here, we make our AWS credential compatible. Now we have a zip containing dependency and our AWS account is connected. As suggested by one stackoverflow answer.\n1 2  aws lambda publish-layer-version --layer-name pandas --zip-file fileb://panda_layer.zip --compatible-runtimes python3.6   But it didnt, so Our DevOps engineer finds a hack to deploy this as a layer. We first push the zip file to a S3 bucket and then publish the layer from there.\n1 2  aws s3 cp layer.zip s3://{{bucket_name}}/layer.zip aws lambda publish-layer-version --layer-name my-layer --description \u0026#34;My layer\u0026#34; --license-info \u0026#34;MIT\u0026#34; --content S3Bucket={{bucket-name}},S3Key=layer.zip --compatible-runtimes python3.6 python3.7 python3.8   yeah, owning one own layer is hard, But we already have two other alternatives.\nStep 6 RUNNNN Run, you could test the model, some database dependency like redis and mongodb should be abale to communicate with AWS lambda otherwise it wont work. But Once you do that, it will surely work and you will see the bueaty.\n1  REPORT RequestId: 5b9ce656-c38c-43c8-9187-515872598c61\tDuration: 3003.21 ms\tBilled Duration: 3000 ms\tMemory Size: 192 MB\tMax Memory Used: 142 MB\tInit Duration: 2202.47 ms\t  You will only get billed for the time you ran for. You could limit the resources, see Memory size and Max Memory used.\nI hope the stats are convincing enough to adopt Lambda function instead a buying bulky Instances.\n","permalink":"http://shekharkoirala.github.io/posts/lambda_function_python/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThe post is a quick guide on \u0026ldquo;How we could use AWS lambda services to deploy some standalone task\u0026rdquo;. This is really helpful when we dont have to buy instances for such task. By using word task, I mean scripts, that could scrap data, or a cron job data aggregator. The BEST thing about the cron job is that , it is way cheaper. A million hits by lambda function is Free in AWS.\u003c/p\u003e","title":"AWS Lambda function for Data Scientist using Python."},{"content":"Introduction I want to create a Blog. But there are some conditions that I want:\n Easy/simple to create The UI should match my style. Based on Git, for future reference.  I chosed Hugo. because it is based on MarkDown.\nWhy MarkDown:  Markdown is simple to learn, with minimal extra characters, so it’s also quicker to write content. Less chance of errors when writing in Markdown. Produces valid XHTML output. Keeps the content and the visual display separate, so you cannot mess up the look of your site. Write in any text editor or Markdown application you like. Markdown is a joy to use  Why Hugo: Hugo is created based on go. A respected and fast programming language. So, the technology stack is nice. beside that, it is based on Markdown. There are few alternatives of Hugo. Like pelican, based on Python: No hard feelings.\nI found a lots of prebuilt themes, which make the boring task easy.\nand you know what , when I know what hugo can do. I need\n proper code formatting in the blog proper user commenting in each posts google analytics animation stuff tags categories search  \u0026mdash;\u0026mdash; blah blah , and I dont need write any html and css. That\u0026rsquo;s awesome.\nInstallation Lets start the work.\n Install Hugo:  For other OS : Install Hugo\n1  brew install hugo   create space:  The naming of folder all yours\n1 2  hugo new site personalBlog cd personalBlog   Add Theme Luckily, hugo has huge collection of themes. Mine one is based on theme: loveit  1 2  git init git submodule add https://github.com/dillonzq/LoveIt.git themes/loveit   Add a new post  1  hugo new posts/my_post.md   yeah , its that easy.\nConfiguration To start the server. lets fix a-little default config.\nopen config.toml in one of the text editor and add this configs there.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  baseURL = \u0026#34;http://example.org/\u0026#34; # [en, zh-cn, fr, ...] determines default content language defaultContentLanguage = \u0026#34;en\u0026#34; # language code languageCode = \u0026#34;en\u0026#34; title = \u0026#34;My New Hugo Site\u0026#34; # Change the default theme to be use when building the site with Hugo theme = \u0026#34;LoveIt\u0026#34; [params] # LoveIt theme version version = \u0026#34;0.2.X\u0026#34; [menu] [[menu.main]] identifier = \u0026#34;posts\u0026#34; # you can add extra information before the name (HTML format is supported), such as icons pre = \u0026#34;\u0026#34; # you can add extra information after the name (HTML format is supported), such as icons post = \u0026#34;\u0026#34; name = \u0026#34;Posts\u0026#34; url = \u0026#34;/posts/\u0026#34; # title will be shown when you hover on this menu link title = \u0026#34;\u0026#34; weight = 1 [[menu.main]] identifier = \u0026#34;tags\u0026#34; pre = \u0026#34;\u0026#34; post = \u0026#34;\u0026#34; name = \u0026#34;Tags\u0026#34; url = \u0026#34;/tags/\u0026#34; title = \u0026#34;\u0026#34; weight = 2 [[menu.main]] identifier = \u0026#34;categories\u0026#34; pre = \u0026#34;\u0026#34; post = \u0026#34;\u0026#34; name = \u0026#34;Categories\u0026#34; url = \u0026#34;/categories/\u0026#34; title = \u0026#34;\u0026#34; weight = 3 # Markup related configuration in Hugo [markup] # Syntax Highlighting (https://gohugo.io/content-management/syntax-highlighting) [markup.highlight] # false is a necessary configuration (https://github.com/dillonzq/LoveIt/issues/158) noClasses = false   Now lets server the site , and check in localhost:1313\n1  hugo serve   Preview Does it look like this ? May be you ask where is the profile in the homepage ? In order to enable that\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  # Home page config [params.home] # LoveIt NEW | 0.2.0 amount of RSS pages rss = 10 # Home page profile [params.home.profile] enable = true # Gravatar Email for preferred avatar in home page gravatarEmail = \u0026#34;\u0026#34; # URL of avatar shown in home page avatarURL = \u0026#34;/images/avatar.png\u0026#34; # LoveIt CHANGED | 0.2.7 title shown in home page (HTML format is supported) title = \u0026#34;\u0026#34; # subtitle shown in home page subtitle = \u0026#34;Personal Blog / Scribbles\u0026#34; # whether to use typeit animation for subtitle typeit = true # whether to show social links social = true # LoveIt NEW | 0.2.0 disclaimer (HTML format is supported) disclaimer = \u0026#34;\u0026#34; # Home page posts [params.home.posts] enable = true # special amount of posts in each home posts page paginate = 6 # LoveIt DELETED | 0.2.0 replaced with hiddenFromHomePage in params.page # default behavior when you don\u0026#39;t set \u0026#34;hiddenFromHomePage\u0026#34; in front matter defaultHiddenFromHomePage = false   More configs can be found here: site-configurations\nDeployment Now lets share what we have created here. But to do that we need to create static site from this markdown. Because only static site is get hosted on the github. No worries, all handled by Hugo.\nCreate a repo in the github based on your \u0026lt;username\u0026gt;/github.io and add it as submodule in the folder.\n1  git submodule add -b master https://github.com/\u0026lt;username\u0026gt;/\u0026lt;username\u0026gt;.github.io.git public   As, suggested by our mighty Hugo, create a deploy.sh file and it here.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  #!/bin/sh  # If a command fails then the deploy stops set -e printf \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\\n\u0026#34; # Build the project. hugo -t loveit # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # Go To Public folder cd public # Add changes to git. git add . # Commit changes. msg=\u0026#34;rebuilding site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master   Basically, it generate static site push the code to github. make sure everything working.Now make the script executable.\n1  chmod +x deploy.sh   1  ./deploy.sh \u0026#34;Your optional commit message\u0026#34;   Done \u0026hellip; !!! checkthe site at \u0026lt;username\u0026gt;.github.io\nFuture We have created a site , but we are not satisfied yet. yeah i know.\n google analytics : Done   Facebook Comments : Done Agolia Search : Done Add Jupyter notebooks in the blog. Using custom domain for the site.  I will look into this topic pretty soon and update in the post.\nReferences Hugo  Install Hugo Quickstart Hugo Host Hugo in github Proper summaries of Blog Hugo themes  loveit  main site Loveit loveit Docs Real world inpiring Example: loveit  markdown  markdown syntax  Add comments to support this Blog.\n","permalink":"http://shekharkoirala.github.io/posts/first_post/","summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eI want to create a Blog. But there are some conditions that I want:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eEasy/simple to create\u003c/li\u003e\n\u003cli\u003eThe UI should match my style.\u003c/li\u003e\n\u003cli\u003eBased on Git, for future reference.\u003c/li\u003e\n\u003c/ol\u003e","title":"Create your own Blog Post"},{"content":"Work Machine Learning Engineer : Identv Software Engineer : Ekbana\nEducation Online Masters in Computer Science - Georgia Tech Electronics and Communication Engineer - IOE, Thapathali Campus\n","permalink":"http://shekharkoirala.github.io/about/","summary":"Work Machine Learning Engineer : Identv Software Engineer : Ekbana\nEducation Online Masters in Computer Science - Georgia Tech Electronics and Communication Engineer - IOE, Thapathali Campus","title":"shekhar koirala"}]